---
title: Vectors and Matrices
slug: Vectors and Matrices
---
<span style="color: #173B72; font-size: 18px;">

> ## Vectors and Matrices TLDR:
> - Vectors and matrices are essential for efficiently storing and processing large data sets, particularly in digital signal processing. 
> - Digital filters, such as moving average filters, help smooth out data fluctuations, like those seen in stock prices. 
>   - For instance, a 2-day moving average filter averages the last two days' prices, while a 5-day filter provides a smoother trend. 
> - The dot product of vectors is crucial for determining similarity; a dot product of zero indicates perpendicular vectors, while a non-zero value suggests similarity. 
>   - This concept is applied in object detection, such as recognizing letters in images by comparing their matrix representations through dot products and cosine similarity.

## Digital Filters 
Vectors and matrices are an efficient way to store and use huge volumes of data. This makes them good for simulators and other computer processing. For example we have spoken about filters which allow some frequencies to pass and remove other frequencies. A CPU is totally digital so it cannot use resistors and capacitors. Instead, if it wants to implement a filter it has to multiply the input "signal" (actually just a stream of numbers) by a set of coefficients. If the data we are talking about is stock prices then this is 1 dimensional data so the coefficients are also going to be 1D so this is more like a vector but if we are using the filter for image processing then the data is going to be 2D so the coefficients also need to be 2D which would then be a matrix.

These digital filters are much easier and cheaper to scale up compared to analog filters so a common practice is actually convert analog data into digital, process it using digital components and then convert it back into the analog domain so that it can be used as part of a control loop.

To better understand digital filters we will do a deep dive into the stock price case. If we take the Nvidia stock price data and do nothing to it, we get a very spiky graph and that is because of random, short-term price fluctuations. 

[![alt text](../evect1.png)]()

If we use something called a moving average filter which is a type of low pass filter we can remove these fluctuations and get a better idea of the trends within the data. The coefficients for a moving average filter are all the same so if you are averaging the last 2 days of data the coefficient vector would be [0.5, 0.5] whereas for 5 days it would be [0.2, 0.2, 0.2, 0.2, 0.2]. The 2 graphs below show a 2-day moving average filter and a 5-day moving average filter. As you can see the 5-day moving average is much smoother whereas we can barely see any difference in the 2-day filter so we can say that a larger averaging window corresponds to a lower cuttoff frequency.

[![alt text](../evect2.png)]()
[![alt text](../evect3.png)]()


## Object Detection
Another common bit of maths that comes up is the dot product. We know that if the dot product is 0, then that means the 2 vectors are perpendicular to each other whereas if it is non-zero that means the vectors are closer to each other. Another way to put this is that the two vectors are similar. We can use the equation <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mrow>
    <mo>(</mo>
    <mi>θ</mi>
    <mo>)</mo>
    <mo>=</mo>
    <mfrac>
      <mrow>
        <mo>&#8290;</mo>
        <mi mathvariant="bold">a</mi>
        <mo>&#8290;</mo>
        <mi mathvariant="bold">b</mi>
      </mrow>
      <mrow>
        <mo>|</mo>
        <mi mathvariant="bold">a</mi>
        <mo>|</mo>
        <mo>&#8290;</mo>
        <mo>|</mo>
        <mi mathvariant="bold">b</mi>
        <mo>|</mo>
      </mrow>
    </mfrac>
  </mrow>
</math>
 to quantify this (if <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mrow>
    <mo>cos</mo>
    <mo>(</mo>
    <mi>θ</mi>
    <mo>)</mo>
    <mo>∼</mo>
    <mn>1</mn>
  </mrow>
</math>
 then same vector otherwise not). This concept is the basis for object detection in images. 

<!-- picture example -->

Let's use the example of converting handwriting into text. If we are looking for the letter 'a' in our image, we would use a picture of the letter 'a' and calculate the dot product between this and the first letter in the image. We would then calculate the determinants of both matrices, divide the dot product by these determinants to give <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mrow>
    <mo>cos</mo>
    <mo>(</mo>
    <mi>θ</mi>
    <mo>)</mo>
  </mrow>
</math> which can then be used to decide if the first letter is an 'a' or if we have to try another letter. This process continues until every letter has been identified.

